{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def check_embedding_size():\n",
    "    # Khởi tạo model embedding\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\"\n",
    "    )\n",
    "    \n",
    "    # Tạo embedding cho một văn bản mẫu\n",
    "    text = \"This is a sample text\"\n",
    "    embedding = embeddings.embed_query(text)\n",
    "    \n",
    "    # Kiểm tra kích thước\n",
    "    print(f\"Embedding dimension: {len(embedding)}\")\n",
    "    \n",
    "    # Kiểm tra shape nếu dùng numpy\n",
    "    import numpy as np\n",
    "    embedding_array = np.array(embedding)\n",
    "    print(f\"Embedding shape: {embedding_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multiple_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\"\n",
    "    )\n",
    "    \n",
    "    texts = [\n",
    "        \"First text\",\n",
    "        \"Second text\",\n",
    "        \"Third text\"\n",
    "    ]\n",
    "    \n",
    "    # Tạo embeddings cho nhiều văn bản\n",
    "    embedded_texts = embeddings.embed_documents(texts)\n",
    "    \n",
    "    # Kiểm tra kích thước cho từng embedding\n",
    "    for i, emb in enumerate(embedded_texts):\n",
    "        print(f\"Text {i+1} embedding size: {len(emb)}\")\n",
    "    \n",
    "    # Kiểm tra tổng thể với numpy\n",
    "    import numpy as np\n",
    "    embedded_array = np.array(embedded_texts)\n",
    "    print(f\"Overall embeddings shape: {embedded_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding analysis: {'dimension': 1024, 'min_value': -0.19820284843444824, 'max_value': 0.23256169259548187, 'mean_value': -0.0007201888914210031, 'memory_size': 4096}\n",
      "Embedding comparison: {'text1_size': 1024, 'text2_size': 1024, 'similarity': 0.7652550986710522}\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingAnalyzer:\n",
    "    def __init__(self, model_name=\"BAAI/bge-m3\"):\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    \n",
    "    def analyze_embedding(self, text):\n",
    "        embedding = self.embeddings.embed_query(text)\n",
    "        \n",
    "        analysis = {\n",
    "            \"dimension\": len(embedding),\n",
    "            \"min_value\": min(embedding),\n",
    "            \"max_value\": max(embedding),\n",
    "            \"mean_value\": sum(embedding) / len(embedding),\n",
    "            \"memory_size\": len(embedding) * 4  # 4 bytes per float\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def compare_embeddings(self, text1, text2):\n",
    "        emb1 = self.embeddings.embed_query(text1)\n",
    "        emb2 = self.embeddings.embed_query(text2)\n",
    "        \n",
    "        import numpy as np\n",
    "        similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "        \n",
    "        return {\n",
    "            \"text1_size\": len(emb1),\n",
    "            \"text2_size\": len(emb2),\n",
    "            \"similarity\": similarity\n",
    "        }\n",
    "\n",
    "# Sử dụng\n",
    "analyzer = EmbeddingAnalyzer()\n",
    "\n",
    "# Phân tích một embedding\n",
    "text = \"Example text for analysis\"\n",
    "analysis = analyzer.analyze_embedding(text)\n",
    "print(\"Embedding analysis:\", analysis)\n",
    "\n",
    "# So sánh hai embedding\n",
    "text1 = \"First text\"\n",
    "text2 = \"Second text\"\n",
    "comparison = analyzer.compare_embeddings(text1, text2)\n",
    "print(\"Embedding comparison:\", comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__ja\n",
      "(('__label__ja',), array([1.00001252]))\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model_path = \"lid.176.bin\"\n",
    "model = fasttext.load_model(model_path)\n",
    "# Test mô hình\n",
    "# result = model.test(\"Xin chào\")\n",
    "# print(\"Độ chính xác:\", result[1])\n",
    "text = \"xin   東京は日本の首都です。世界有数の大都市であり、政治、経済、文化の中心地です。 多くの観光名所があり、毎年多くの観光客が訪れています。東京スカイツリーや浅草寺など、伝統と現代が共存する街並みが特徴です\"\n",
    "predictions = model.predict(text, k=1)\n",
    "print(predictions[0][0])\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backendenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
